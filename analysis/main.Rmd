---
title: "Advanced data journalism: Doing more with R"
author: "Fernando Millan Villalobos"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    echo: TRUE
    warning: FALSE
    message: FALSE
    highlight: pygments
    theme: paper
    df_print: kable
    toc: yes
    toc_depth: 4
    number_sections: yes
    toc_float: 
      collapsed: yes
      smooth_scroll: false
# knit: (function(inputFile, encoding) {
  # rmarkdown::render(inputFile, encoding = encoding, output_dir = "../", output_file = "index") })
# favicon: img/favicon.ico
# url: "https://walker-data.com/census-r"
# cover-image: "04-visualizing-census-data_files/figure-html/visualize-error-bars-1.png"
# description: "This book is an overview of how practitioners can acquire, wrangle, visualize, and model US Census data with the R programming language."
---

```{r, include=FALSE}
## By default, show code for all chunks in the knitted document,
## as well as the output. To override for a particular chunk
## use echo = FALSE in its options.
knitr::opts_chunk$set(
   echo=TRUE, message=FALSE, warning=FALSE
)
```

```{r, echo=FALSE}
# CONFIG
user_name <- "fernandomillanvillalobos" # your Git username (only needed if
# you want to deploy to GH pages)
project_name <- "adjclass-nando" # adapt!
package_date <- "2022-05-01" # date of the CRAN snapshot that
# the checkpoint package uses
r_version <- "4.2.1" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (r_version != paste0(version$major, ".", version$minor)) {
  stop("ERROR: specified R version does not match currently used.")
}
```

# Notes

This report was generated on `r Sys.time()`. R version: `r paste0(version$major, ".", version$minor)` on `r version$platform`. For this report, CRAN packages as of `r package_date` were used.

...

## R-Script & data

The preprocessing and analysis of the data was conducted in the [R project for statistical computing](https://www.r-project.org/). The RMarkdown script used to generate this document and all the resulting data can be downloaded [under this link](http://`r user_name`.github.io/`r project_name`/). Through executing `main.Rmd`, the herein described process can be reproduced and this document can be generated. In the course of this, data from the folder `input` will be processed and results will be written to `output`. The html on-line version of the analysis can be accessed through this [link](https://`r user_name`.github.io/`r project_name`/). 

## GitHub

The code for the herein described process can also be freely downloaded from [https://github.com/`r user_name`/`r project_name`](https://github.com/`r user_name`/`r project_name`). 

## License

...

## Data description of output files

#### `abc.csv` (Example)

| Attribute | Type | Description |
|-------|------|-----------------------------------------------------------------------------|
| a | Numeric | ... |
| b | Numeric | ... |
| c | Numeric |  ... |

...

# Set up

```{r, echo=FALSE}
detach_all_packages <- function() {
  basic_packages_blank <-  c("stats",
                             "graphics",
                             "grDevices",
                             "utils",
                             "datasets",
                             "methods",
                             "base")
  basic_packages <- paste("package:", basic_packages_blank, sep = "")

  package_list <- search()[
    ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]

  package_list <- setdiff(package_list, basic_packages)

  if (length(package_list) > 0)  for (package in package_list) {
    detach(package, character.only = TRUE, unload = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}

detach_all_packages()

# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
  print("WARNING: No working directory specified for current user")
} else {
  setwd(path_to_wd)
}

# suppress scientific notation
options(scipen = 999)

# suppress summarise info
options(dplyr.summarise.inform = FALSE)

# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
  detach_all_packages()
}
```

## Define packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse)
library(tidylog)
library(jsonlite)
library(lintr)
library(rmarkdown)
library(rio)
library(cowplot)
library(extrafont)
library(ggrepel)
library(scales)
library(remotes)
library(lubridate)
library(rvest)
library(httr)
library(tidycensus)
library(janitor)",
file = "manifest.R")
```

## Install packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
  if (!require(devtools)) {
    install.packages("devtools", repos = "http://cran.us.r-project.org")
    require(devtools)
  }
  devtools::install_github("RevolutionAnalytics/checkpoint",
                           ref = "v0.3.2", # could be adapted later,
                           # as of now (beginning of July 2017
                           # this is the current release on CRAN)
                           repos = "http://cran.us.r-project.org")
  require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
  dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshot_date = package_date,
           project = path_to_wd,
           verbose = T,
           scanForPackages = T,
           use.knitr = F,
           R.version = r_version)
rm(package_date)
```

## Load packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
source("manifest.R")
unlink("manifest.R")
sessionInfo()
```

## Load additional scripts

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if you want to outsource logic to other script files, see README for 
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
knitr::read_chunk("scripts/outliers.R")
source("scripts/outliers.R")
```

# Module 1

In this lesson, we’re going to start exploring data with the package dplyr.

- It’s designed to work with data frames, which is what journalists are used to
- Great for data exploration and transformation
- Intuitive to write and easy to read, especially when using the “chaining” syntax of pipes
- These are the functions/data analysis verbs we’ll be going over:

- `filter()`
- `select()`
- `arrange()`
- `mutate()`
- `summarize()` plus `group_by()`

```{r, fig.cap=c("Module 1: Analyzing data with R"), out.width="100%", out.height="600px", echo=FALSE, fig.show='hold'}
knitr::include_graphics("input/pdf/ADJ_Class_1.pdf")  
```
```{r}
# getting the data https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2
df <- read_csv("https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.csv") %>% 
  glimpse()

# getting the range
range(df$incidentBeginDate)

# exploring the data with table()
table(df$incidentType)
# or with count()
incident_types <- count(df, incidentType, name = "total") # rename the default "n" column
incident_types

# arranging the data
incident_types_arranged <- arrange(incident_types, desc(total))
incident_types_arranged

# pipeing it all
incident_types_arranged <- df %>%
  count(incidentType, name = "total") %>%
  arrange(desc(total))
incident_types_arranged

# filtering
incident_types_arranged_filtered <- incident_types_arranged %>%
  filter(incidentType != "Biological")
incident_types_arranged_filtered

# filtering by multiple values
incident_types_arranged %>%
  filter(incidentType == "Tornado" | incidentType == "Hurricane")

# using an array to filter
disaster_array <- c("Tornado", "Hurricane", "Flood")
incident_types_arranged %>%
  filter(incidentType %in% disaster_array)

# missing values
head(is.na(df$incidentType))
sum(is.na(df$incidentType))

# using select()
nrow(df)
colnames(df)

df_narrow <- df %>%
  select(
    femaDeclarationString, state, declarationDate,
    fyDeclared, designatedArea, incidentType
  )
colnames(df_narrow)

# using slice()
rev_chron_floods <- df %>%
  filter(incidentType == "Flood") %>%
  arrange(desc(declarationDate)) %>%
  slice(1:5)
rev_chron_floods

# using mutate()
floods <- df %>%
  filter(incidentType == "Flood")
floods_adjusted <- floods %>%
  mutate(year = year(declarationDate)) %>%
  select(year, declarationDate, fyDeclared)
floods_adjusted

# using summarize()
floods %>%
  mutate(year = year(declarationDate)) %>%
  group_by(year) %>%
  summarize(total = n())

# using case_when()
floods_match <- floods_adjusted %>%
  mutate(
    year_match =
      case_when(
        year == fyDeclared ~ "Match",
        TRUE ~ "Not a match"
      )
  ) %>%
  group_by(year_match) %>%
  summarize(total = n())
floods_match

# using pull()
floods_match_count <- floods_match %>%
  filter(year_match == "Not a match") %>%
  pull(total)
floods_match_count

# getting the pct
total_obs <- nrow(floods)
floods_match_count / total_obs * 100
round(floods_match_count / total_obs * 100, 1)

# Which year had the most floods declarations?
annual_floods <- df %>%
  filter(incidentType == "Flood") %>%
  mutate(year = year(declarationDate)) %>%
  group_by(year) %>%
  summarize(total = n()) %>%
  arrange(desc(total))
annual_floods

# Which state has had the most flooding declared disasters?
state_floods <- df %>%
  filter(incidentType == "Flood") %>%
  group_by(state) %>%
  summarize(floods = n()) %>%
  arrange(desc(floods))
state_floods
```
# Module 2

Let’s take a moment to talk about the significance of __tidy__ data. It’s the prefix to a lot of the packages and functions we’re using in this class. But it’s also a philosophy when approaching the structure of data.

There’s an ideal structure for how to stack your data.

And that’s with

- Each __variable__ is in its own __column__
- Each __case__ is in its own __row__
- Each __value__ is in its own __cell__

A join combines two data sets by adding the columns of one data set alongside the columns of the other, usually some of the rows of the second data set along with some rows of the first data set.

A successful join requires something consistent between two data sets to match on: __keys__.

The function that’s used most often is `left_join()` because you have one main data set you’d like to supplement with additional columns.

The function works like this:

If the two data frames you want to join have __the same name__:

`left_join(data_frame1, data_frame2, by="shared_column_name")`

If the two data frames you want to join have __different names__:

`left_join(data_frame1, data_frame2, by=c("df1_column"="df_2_column"))`

Notice that the `c()` argument in the second example is different from how we’ve used it before as combine. The `=` column matching operator is specific to `_join()` functions.

Now there are a few other joins that have their uses.

- `right_join()`
- `full_join()`
- `semi_join()`
- `anti_join()`

There are many wonderful functions in the __stringr__ package that you do things like detect patterns, see if strings start with with a pattern, or split or join or substitute strings.

Nearly every news story that involves data analysis can be derived from one these formulas.

- Difference
  - x - y
- Percent
  - x / (x + y) * 100
- Percent change
  - (new - old)/old * 100
- Per Capita
  - x / population * some multiplier to raise result to a round number

```{r, fig.cap=c("Module 2: Joins and Strings"), out.width="100%", out.height="600px", echo=FALSE, fig.show='hold'}
knitr::include_graphics("input/pdf/ADJ_Class_2.pdf")  
```

```{r}
census_api_key("02898df1b52d892523a165c11b8b9630e646f22b", install = TRUE, overwrite = TRUE)
county_pop <- get_acs(geography = "county", variables = "B01003_001", year = 2020)
df <- read_csv("https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.csv")

# combining strings
df_new <- df %>%
  mutate(GEOID = str_c(fipsStateCode, fipsCountyCode))

# joining data frames
joined_new <- left_join(df_new, county_pop, by = "GEOID")
glimpse(joined_new)

# summarizing data
joined_new %>%
  group_by(incidentType) %>%
  summarize(
    declarations = n(),
    avg_pop = mean(estimate, na.rm = T),
    median_pop = median(estimate, na.rm = T)
  ) %>%
  arrange(desc(avg_pop)) %>%
  slice(1:5)

# wrangling data to compare the current months of 2022 with the past months (otherwise we’d be comparing 12 months of data in 2021 to 8 in 2022 which would be misleading)
joined_new %>%
  filter(state == "KY") %>%
  filter(incidentType == "Flood") %>%
  mutate(year = year(incidentBeginDate)) %>%
  # extracting months
  mutate(month = month(incidentBeginDate)) %>%
  # only paying attention to months in current year of data set
  filter(month %in% c(1:8)) %>%
  filter(year == 2020 | year == 2021 | year == 2022) %>%
  group_by(year) %>%
  summarize(
    declarations = n(),
    avg_pop = mean(estimate, na.rm = T),
    median_pop = median(estimate, na.rm = T)
  )

# getting percent
# x / (x + y) * 100
old <- 50 / (50 + 20) * 100
new <- 20 / (20 + 50) * 100

# getting percent change
#  (new - old)/old * 100
(new - old) / old * 100
```

# Linting

The code in this RMarkdown is linted with the [lintr package](https://github.com/jimhester/lintr), which is based on the  [tidyverse style guide](http://style.tidyverse.org/). 

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
# lintr::lint("main.Rmd", linters =
#               lintr::with_defaults(
#                 commented_code_linter = NULL,
#                 trailing_whitespace_linter = NULL
#                 )
#             )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
```
